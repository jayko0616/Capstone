{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zkr9J9UfayDw","outputId":"15836328-cbd0-454d-e186-f96f4c20fdde","executionInfo":{"status":"ok","timestamp":1718176358212,"user_tz":-540,"elapsed":12430,"user":{"displayName":"asdf","userId":"09707657162804162226"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorboardX\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.0)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.6.2.2\n"]}],"source":["!pip install tensorboardX"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nbU1k78zKJe1","executionInfo":{"status":"ok","timestamp":1718176378865,"user_tz":-540,"elapsed":20656,"user":{"displayName":"asdf","userId":"09707657162804162226"}},"outputId":"b1f48ed1-a657-4535-97bb-7a4eeccc1974"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd '/content/drive/MyDrive/Capstone/ai'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvANZwDYcjyu","outputId":"65b0f896-5c78-47fb-b5c2-78ac5964d702","executionInfo":{"status":"ok","timestamp":1718176378865,"user_tz":-540,"elapsed":4,"user":{"displayName":"asdf","userId":"09707657162804162226"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Capstone/ai\n"]}]},{"cell_type":"code","source":["!git config --global user.name 'Yong'\n","!git config --global user.email 'whitasrgrey@gmail.com'"],"metadata":{"id":"7vJqGIG4Jsdl","executionInfo":{"status":"ok","timestamp":1718176380723,"user_tz":-540,"elapsed":1861,"user":{"displayName":"asdf","userId":"09707657162804162226"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!git pull origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZPG0fm3QZNjy","executionInfo":{"status":"ok","timestamp":1718176408425,"user_tz":-540,"elapsed":27704,"user":{"displayName":"asdf","userId":"09707657162804162226"}},"outputId":"f5cef723-bda5-4853-ed63-9999be7ab8bf"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["remote: Enumerating objects: 7, done.\u001b[K\n","remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n","remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n","remote: Total 4 (delta 2), reused 4 (delta 2), pack-reused 0\u001b[K\n","Unpacking objects: 100% (4/4), 453 bytes | 1024 bytes/s, done.\n","From https://github.com/Aggressive-3Back/ai\n"," * branch            main       -> FETCH_HEAD\n","   33cf6f6..c49f9d2  main       -> origin/main\n","Updating 33cf6f6..c49f9d2\n","Fast-forward\n"," data/ratings.csv | 10 \u001b[32m++++++++++\u001b[m\n"," 1 file changed, 10 insertions(+)\n"]}]},{"cell_type":"markdown","source":["# 데이터 증강"],"metadata":{"id":"l9d_HVYJ9hZN"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# 기존 데이터 로드\n","data = pd.read_csv('./data/ratings.csv', sep=\";\")\n","new_column_order = ['user_id', 'item_id', 'rating']\n","data = data[new_column_order]\n","\n","# 유저 및 가게 리스트 생성\n","user_ids = data['user_id'].unique()\n","item_ids = data['item_id'].unique().tolist()\n","\n","# 가게 수를 200개로 확장\n","max_item_id = max(item_ids)\n","item_ids = list(range(1, 201))\n","\n","# 유저별 네거티브 샘플 생성\n","neg_samples = []\n","\n","for user_id in user_ids:\n","    user_items = data[data['user_id'] == user_id]['item_id'].tolist()\n","    neg_items = list(set(item_ids) - set(user_items))\n","\n","    if len(neg_items) < 100:\n","        neg_items = np.random.choice(neg_items, len(neg_items), replace=False)\n","    else:\n","        neg_items = np.random.choice(neg_items, 100, replace=False)\n","\n","    for item in neg_items:\n","        neg_samples.append([user_id, item, 0])\n","\n","# 네거티브 샘플을 데이터프레임으로 변환\n","neg_samples_df = pd.DataFrame(neg_samples, columns=['user_id', 'item_id', 'rating'])\n","\n","# 원본 데이터와 네거티브 샘플을 결합\n","augmented_data = pd.concat([data, neg_samples_df], ignore_index=True)\n","\n","# 데이터셋 저장\n","augmented_data.to_csv('./data/augmented_data.csv', index=False)"],"metadata":{"id":"2exn4-Tu9X_E","executionInfo":{"status":"ok","timestamp":1718176408942,"user_tz":-540,"elapsed":532,"user":{"displayName":"asdf","userId":"09707657162804162226"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# 학습"],"metadata":{"id":"fASbDIRL9kiI"}},{"cell_type":"code","source":["import os\n","import time\n","import random\n","import math\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","from tensorboardX import SummaryWriter\n","from sklearn.model_selection import train_test_split\n","\n","# 설정값 정의\n","config = {\n","    \"model_path\": \"./models/\",\n","    \"data_path\": './data/augmented_data.csv',\n","}\n","\n","args = {\n","    \"batch_size\":16,\n","    \"dropout\": 0,\n","    \"epochs\": 10,\n","    \"factor_num\": 8,\n","    \"gpu\": \"0\",\n","    \"layers\": [64, 32, 16, 8],\n","    \"lr\": 0.0001,\n","    \"num_ng\": 4,\n","    \"num_ng_test\": 50,\n","    \"out\": True,\n","    \"seed\": 42,\n","    \"top_k\": 10,\n","}\n","\n","# 시드 설정 함수\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(args['seed'])\n","\n","# 데이터셋 클래스 정의\n","class Rating_Dataset(torch.utils.data.Dataset):\n","    def __init__(self, user_list, item_list, rating_list):\n","        super(Rating_Dataset, self).__init__()\n","        self.user_list = user_list\n","        self.item_list = item_list\n","        self.rating_list = rating_list\n","\n","    def __len__(self):\n","        return len(self.user_list)\n","\n","    def __getitem__(self, idx):\n","        user = self.user_list[idx]\n","        item = self.item_list[idx]\n","        rating = self.rating_list[idx]\n","\n","        return (\n","            torch.tensor(user, dtype=torch.long),\n","            torch.tensor(item, dtype=torch.long),\n","            torch.tensor(rating, dtype=torch.float)\n","        )\n","\n","# 데이터 로드 및 전처리\n","def load_data(config, args):\n","    data = pd.read_csv(config['data_path'])\n","\n","    user_list = data['user_id'].tolist()\n","    item_list = data['item_id'].tolist()\n","    rating_list = data['rating'].tolist()\n","\n","    train_data, test_data = train_test_split(data, test_size=0.2, random_state=args['seed'])\n","\n","    train_dataset = Rating_Dataset(train_data['user_id'].tolist(), train_data['item_id'].tolist(), train_data['rating'].tolist())\n","    test_dataset = Rating_Dataset(test_data['user_id'].tolist(), test_data['item_id'].tolist(), test_data['rating'].tolist())\n","\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args['batch_size'], shuffle=True, num_workers=2)\n","    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args['batch_size'], shuffle=False, num_workers=2)\n","\n","    return train_loader, test_loader, len(user_list), len(item_list)\n","\n","train_loader, test_loader, user_num, item_num = load_data(config, args)\n","\n","\n","def get_hit_ratio(recommended_items, actual_item):\n","    if actual_item in recommended_items:\n","        return 1\n","    return 0\n","\n","def get_ndcg(recommended_items, actual_item):\n","    if actual_item in recommended_items:\n","        index = recommended_items.index(actual_item)\n","        return math.log(2) / math.log(index + 2)\n","    return 0\n","\n","# NeuMF 모델 클래스 정의\n","class NeuMF(nn.Module):\n","    def __init__(self, user_num, item_num, factor_num, layers, dropout):\n","        super(NeuMF, self).__init__()\n","        self.user_embedding_mf = nn.Embedding(user_num, factor_num)\n","        self.item_embedding_mf = nn.Embedding(item_num, factor_num)\n","        self.user_embedding_mlp = nn.Embedding(user_num, factor_num * 2)\n","        self.item_embedding_mlp = nn.Embedding(item_num, factor_num * 2)\n","\n","        MLP_modules = []\n","        input_size = factor_num * 4\n","        for layer_size in layers:\n","            MLP_modules.append(nn.Linear(input_size, layer_size))\n","            MLP_modules.append(nn.ReLU())\n","            MLP_modules.append(nn.Dropout(dropout))\n","            input_size = layer_size\n","        self.MLP_layers = nn.Sequential(*MLP_modules)\n","        self.predict_layer = nn.Linear(factor_num + layers[-1], 1)\n","\n","    def forward(self, user, item):\n","        user_embedding_mf = self.user_embedding_mf(user)\n","        item_embedding_mf = self.item_embedding_mf(item)\n","        mf_vector = user_embedding_mf * item_embedding_mf\n","\n","        user_embedding_mlp = self.user_embedding_mlp(user)\n","        item_embedding_mlp = self.item_embedding_mlp(item)\n","        mlp_vector = torch.cat([user_embedding_mlp, item_embedding_mlp], dim=-1)\n","        mlp_vector = self.MLP_layers(mlp_vector)\n","\n","        vector = torch.cat([mf_vector, mlp_vector], dim=-1)\n","        prediction = self.predict_layer(vector)\n","        return prediction.view(-1,1)  # Ensure the output is always a 1D tensor\n","\n","# Adjust metrics function to handle scalar predictions\n","def metrics(model, test_loader, top_k, device):\n","    HR, NDCG = [], []\n","\n","    for user, item, _ in test_loader:\n","        user = user.to(device)\n","        item = item.to(device)\n","\n","        with torch.no_grad():\n","            prediction = model(user, item).squeeze()\n","            if prediction.dim() == 0:  # Handle scalar prediction\n","                prediction = prediction.unsqueeze(0)\n","\n","        if prediction.size(0) == 0:\n","            continue\n","\n","        k = min(top_k, prediction.size(0))\n","        _, indices = torch.topk(prediction, k)\n","        recommended_items = torch.take(item, indices).cpu().numpy().tolist()\n","        actual_items = item.cpu().numpy().tolist()\n","\n","        for actual_item in actual_items:\n","            HR.append(get_hit_ratio(recommended_items, actual_item))\n","            NDCG.append(get_ndcg(recommended_items, actual_item))\n","\n","    return np.mean(HR), np.mean(NDCG)\n","\n","# 모델 훈련 및 평가\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = NeuMF(user_num, item_num, args['factor_num'], args['layers'], args['dropout']).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n","criterion = nn.BCEWithLogitsLoss()\n","writer = SummaryWriter()\n","\n","best_hr, best_ndcg, best_epoch = 0, 0, 0\n","for epoch in range(args['epochs']):\n","    model.train()\n","    start_time = time.time()\n","    for user, item, label in train_loader:\n","        user = user.to(device)\n","        item = item.to(device)\n","        label = label.to(device).view(-1, 1)  # 여기서 label 크기를 맞춰줍니다.\n","\n","        model.zero_grad()\n","        prediction = model(user, item)\n","        loss = criterion(prediction, label)\n","        loss.backward()\n","        optimizer.step()\n","        writer.add_scalar('loss/Train_loss', loss.item(), epoch)\n","\n","    model.eval()\n","    HR, NDCG = metrics(model, test_loader, args['top_k'], device)\n","    writer.add_scalar('Performance/HR@10', HR, epoch)\n","    writer.add_scalar('Performance/nDCG@10', NDCG, epoch)\n","\n","    elapsed_time = time.time() - start_time\n","    print(\"The time elapse of epoch {:03d}\".format(epoch) + \" is: \" +  time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n","    print(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(HR, NDCG))\n","\n","    if HR > best_hr:\n","        best_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n","        if args['out']:\n","            if not os.path.exists(config['model_path']):\n","                os.mkdir(config['model_path'])\n","            torch.save({\n","    'user_num': user_num,\n","    'item_num': item_num,\n","    'model_state_dict': model.state_dict()\n","}, os.path.join(config['model_path'], 'NeuMF_state_dict.pth'))\n","writer.close()"],"metadata":{"id":"Uf9w3GOka7gr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"__M5aG5KJ1Qh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git commit -m 'update system'\n","!git push origin main"],"metadata":{"id":"Vj5XRFfVJ64g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %load_ext tensorboard\n","# %tensorboard --logdir=runs"],"metadata":{"id":"IFjXZkyFcgXJ"},"execution_count":null,"outputs":[]}]}